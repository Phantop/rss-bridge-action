<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" version="2.0">
  <channel>
    <title>Phoronix</title>
    <description>Phoronix</description>
    <link>https://www.phoronix.com/</link>
    <atom:link rel="alternate" type="text/html" href="https://www.phoronix.com/"/>
    <atom:link rel="self" type="application/atom+xml" href="http://localhost:8080/?action=display&amp;format=Mrss&amp;bridge=PhoronixBridge"/>
    <image>
      <url>https://www.phoronix.com/favicon.ico</url>
      <title>Phoronix</title>
      <link>https://www.phoronix.com/</link>
    </image>
    <item>
      <title>An Initial Benchmark Of Bcachefs vs. Btrfs vs. EXT4 vs. F2FS vs. XFS On Linux 6.11</title>
      <link>https://www.phoronix.com/review/linux-611-filesystems</link>
      <guid isPermaLink="true">https://www.phoronix.com/review/linux-611-filesystems</guid>
      <pubDate>Fri, 09 Aug 2024 15:55:42 +0000</pubDate>
      <description>&lt;div class="content"&gt;   &lt;p&gt;A number of Phoronix readers have been requesting a fresh re-test of the experimenta; Bcachefs file-system against other Linux file-systems on the newest kernel code. Your wish has been granted today with a fresh round of benchmarking across Bcachefs, Btrfs, EXT4, F2FS, and XFS using the Linux 6.11-rc2 kernel. This round of testing was carried out on the newly-released &lt;a href="https://www.phoronix.com/review/solidigm-d7-ps1010"&gt;Solidigm D7-PS1010 PCIe 5.0 NVMe SSDs&lt;/a&gt; that offer very speedy performance for modern Linux desktops and servers.&lt;/p&gt;  &lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=linux-611-filesystems&amp;image=linux_611_solidigm_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=linux-611-filesystems&amp;image=linux_611_solidigm_med" alt="Solidigm 7.6TB PCIe 5.0 NVMe SSD" /&gt;&lt;/a&gt;&lt;/p&gt;  &lt;p&gt;This round of testing was done on an AMD EPYC 8534P "Siena" server with the SOLIDIGM SB5PH27X076T (D7-PS1010 7.6TB PCIe 5.0 NVMe SSD) storage being used for testing each file-system. Each file-system was freshly formatted and mounted using the default mount options of each file-system under test. All tests were done using the Linux 6.11-rc2 kernel atop an Ubuntu 24.04 LTS host.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="https://phoronix.com/benchmark/result/linux-611-file-systems/result.svgz" alt="Linux 6.11 File-Systems" /&gt;&lt;/div&gt;  &lt;p&gt;Bcachefs was working well this round without any errors or issues to note, it's stabilized quite a bit in the recent kernel releases. The other Linux file-systems also continued to operate without any issues to point out. OpenZFS wasn't used for this round of testing since it doesn't yet support the Linux 6.11 (or 6.10) kernels in released form.&lt;/p&gt;  &lt;/div&gt;&lt;div class="content"&gt;   &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/linux-611-file-systems/sqlite-4.svgz" alt="SQLite benchmark with settings of Threads / Copies: 4. XFS was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;First when carrying out some basic SQLite write tests with four concurrent databases, XFS and EXT4 were easily the fastest in their out-of-the-box form. The copy-on-write file-systems were slower for the databases with Btrfs by far being the slowest while Bcachefs was surprisingly in third just a short distance behind XFS and EXT4.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/linux-611-file-systems/flexible-io-tester-rand-read-io_uring-yes-4kb-32-1.svgz" alt="Flexible IO Tester benchmark with settings of Type: Random Read, Engine: IO_uring, Direct: Yes, Block Size: 4KB, Job Count: 32, Disk Target: Default Test Directory. XFS was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;For 4K random reads with FIO, Btrfs in its default configuration was the slowest while Bcachefs was mid-way between the XFS / EXT4 / F2FS performance level and that of Btrfs.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/linux-611-file-systems/flexible-io-tester-rand-write-io_uring-yes-4kb-32-1.svgz" alt="Flexible IO Tester benchmark with settings of Type: Random Write, Engine: IO_uring, Direct: Yes, Block Size: 4KB, Job Count: 32, Disk Target: Default Test Directory. F2FS was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;When it came to FIO random writes with 32 concurrent jobs, Bcachefs was the slowest right behind Btrfs. F2FS was yielding the fastest performance with a nice boost over EXT4 and XFS.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/linux-611-file-systems/flexible-io-tester-seq-write-io_uring-yes-2mb-32.svgz" alt="Flexible IO Tester benchmark with settings of Type: Sequential Write, Engine: IO_uring, Direct: Yes, Block Size: 2MB, Job Count: 32, Disk Target: Default Test Directory. F2FS was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;For sequential writes, Bcachefs was the slowest while Btrfs was moderately faster while F2FS / XFS / EXT4 were all running about the same write speed in this default mount option (out of the box) testing on the PCIe 5.0 SSD from Solidigm.&lt;/p&gt;  &lt;/div&gt;&lt;div class="content"&gt;   &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/linux-611-file-systems/dbench-12.svgz" alt="Dbench benchmark with settings of Client Count: 12. F2FS was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;For Dbench, F2FS again had a lovely first place finish followed by XFS and then EXT4. Bcachefs and Btrfs were back in last with at least Bcachefs performing a fair amount better than Btrfs for this storage benchmark.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/linux-611-file-systems/cockroachdb-kv-50-reads-256.svgz" alt="CockroachDB benchmark with settings of Workload: KV, 50% Reads, Concurrency: 256. XFS was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;For the Cockroach database XFS and F2FS were effectively tied for first while Btrfs was the slowest and Bcachefs was mid-way between the Btrfs CoW and EXT4 / F2FS / XFS.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/linux-611-file-systems/mariadb-oltp_update_non_index-64.svgz" alt="MariaDB benchmark with settings of Test: oltp_update_non_index, Threads: 64. F2FS was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/linux-611-file-systems/mariadb-mariadb-slap-32.svgz" alt="MariaDB mariadb-slap benchmark with settings of Clients: 32. EXT4 was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;Bcachefs with its copy-on-write design impressed for the out-of-the-box performance in MariaDB that it performed closer to EXT4 / XFS / F2FS than Btrfs out-of-the-box.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/linux-611-file-systems/postgresql-100-1000-read-write.svgz" alt="PostgreSQL benchmark with settings of Scaling Factor: 100, Clients: 1000, Mode: Read Write. XFS was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/linux-611-file-systems/postgresql-100-1000-read-write-average-latency.svgz" alt="PostgreSQL benchmark with settings of Scaling Factor: 100, Clients: 1000, Mode: Read Write, Average Latency. XFS was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;For PostgreSQL, Bcachefs also continued performing a fair amount better than Btrfs.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/linux-611-file-systems/geometric-mean-of-all-test-results-result-composite-l61fs.svgz" alt="Geometric Mean Of All Test Results benchmark with settings of Result Composite, Linux 6.11 File-Systems. XFS was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;From this testing on Linux 6.11-rc2, Bcachefs continues looking better with each new kernel version. There were some nice improvements since the last time I carried out Bcachefs testing and it performed measurably better in a number of benchmarks than Btrfs. XFS and EXT4 remained tied in first place overall for those curious about the out-of-the-box Linux file-system performance without any additional tuning/tweaks.&lt;/p&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Linux's DRM Power Saving Policy Gets Reverted For Now</title>
      <link>https://www.phoronix.com/news/DRM-Revert-Power-Saving-Prop</link>
      <guid isPermaLink="true">https://www.phoronix.com/news/DRM-Revert-Power-Saving-Prop</guid>
      <pubDate>Fri, 09 Aug 2024 12:45:42 +0000</pubDate>
      <description>&lt;div class="content"&gt; &lt;div style="float: left; padding: 0 10px 10px;"&gt;&lt;img alt="HARDWARE" src="https://www.phoronix.com/assets/categories/hardware.webp" width="100" height="100" /&gt;&lt;/div&gt; Submitted for DRM-Next last week with intentions of getting it into the Linux 6.12 kernel was &lt;a href="https://www.phoronix.com/news/Linux-6.12-Power-Saving-Policy"&gt;a new DRM "power saving policy" property&lt;/a&gt;. The intent was for this new monitor/display connector property to indicate whether power saving features should be used that could compromise the experience intended by the desktop compositor. But one week later this property is now set to be removed as it's been deemed immature. &lt;br /&gt; &lt;br /&gt;The Power Saving Policy for the connector currently can indicate whether the driver should require color accuracy and in turn for the driver/hardware to disable power saving features that could affect color fidelity. Another policy option is for requiring low-latency to disable power saving features that affect the display latency like Panel Self Refresh (PSR).  While the ultimate intention of this feature is worthwhile, the support for the DRM core property and the AMDGPU driver integration is being reverted just one week after it was submitted to DRM-Next. &lt;br /&gt;&lt;p align="center"&gt;&lt;img src="https://www.phoronix.net/image.php?id=amd-radeon-rx7900-gre&amp;image=amd_rx7900gre_4_med" alt="Radeon display connections" /&gt;&lt;/p&gt; &lt;br /&gt;Developers have determined the property in its current form doesn't meet user-space requirements and that merging the property to the mainline kernel should wait until there is a user-space solution properly ready for merging. &lt;br /&gt; &lt;br /&gt;AMD engineer Harry Wentland &lt;a href="https://lists.freedesktop.org/archives/amd-gfx/2024-August/112106.html"&gt;commented&lt;/a&gt; last week on the mailing list after issues were raised over this Power Saving Policy property: &lt;br /&gt;&lt;blockquote&gt;"I agree we should revert the KMS property until we have a userspace implementation that is reviewed and ready to be merged. It was merged based on a misunderstanding and shouldn't have been merged. &lt;br /&gt; &lt;br /&gt;I don't think we should revert the sysfs property. The power savings to end-users can be significant. I would like to see compositors take control if it via the KMS property. &lt;br /&gt;... &lt;br /&gt;We have a good handful of widely used compositors. We have one PPD with a replacement for it in the works. A sysfs allows all users to get the power benefits even if compositors don't explicitly enable support for power saving features in KMS. The goal of PPD and co. is power savings while that is not always a primary goal for all compositors (even though compositors play a large role in a system's power usage)."&lt;/blockquote&gt; &lt;br /&gt;Thus with today's &lt;a href="https://lore.kernel.org/dri-devel/20240809071241.GA222501@localhost.localdomain/T/#u"&gt;drm-misc-next pull&lt;/a&gt; that Power Saving Policy property is being removed.&lt;/div&gt;</description>
    </item>
    <item>
      <title>Linux On The Snapdragon X1 Microsoft Surface Laptop 7, But Critical Features Missing</title>
      <link>https://www.phoronix.com/news/Microsoft-Surface-7-X1-Linux-DT</link>
      <guid isPermaLink="true">https://www.phoronix.com/news/Microsoft-Surface-7-X1-Linux-DT</guid>
      <pubDate>Fri, 09 Aug 2024 11:05:00 +0000</pubDate>
      <description>&lt;div class="content"&gt; &lt;div style="float: left; padding: 0 10px 10px;"&gt;&lt;img alt="MICROSOFT" src="https://www.phoronix.com/assets/categories/microsoft.webp" width="100" height="100" /&gt;&lt;/div&gt; A Qualcomm engineer has posted the Linux kernel patches for adding the DeviceTree to support the Microsoft Surface Laptop 7 devices powered by the new Qualcomm Snapdragon X1 SoCs. This allows Linux to run on these new Snapdragon X1-powered Microsoft laptops but as with the other devices there are a number of support caveats that for most end-users will be a showstopper. &lt;br /&gt; &lt;br /&gt;Recently there's been work for adding various DeviceTree files for supporting different Qualcomm Snapdragon X1 laptops that have debuted over the summer. Sadly, the DeviceTree additions are needed for these initial Snapdragon X1 laptops rather than relying on ACPI or other means of standardized enumeration. With Linux 6.11 there is &lt;a href="https://www.phoronix.com/news/Linux-6.11-SoC-Platforms"&gt;initial support for the ASUS Vivobook S15 and Lenovo Yoga Slim7x&lt;/a&gt;, more recently has been &lt;a href="https://www.phoronix.com/news/Linux-X1E-ThinkPad-T14s-Gen-6"&gt;patches for enabling the X1 Elite powered ThinkPad T14s Gen 6&lt;/a&gt;, and now as of this morning also DT support for the Microsoft Surface Laptop 7 devices. &lt;br /&gt;&lt;p align="center"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=ms_surface_laptop_7" alt="Surface Laptop 7" /&gt;&lt;/p&gt; &lt;br /&gt;The patches add support for the Surface Laptop 7 "romulus13" and "romulus15" models. But as we've seen with other Snapdragon X1 Elite laptops on Linux, there are a number of support caveats at present. The Microsoft Surface Laptop 7 support on Linux comes with the following notice: &lt;br /&gt;&lt;blockquote&gt;"Add support for Surface Laptop 7 machines, based on X1E80100. &lt;br /&gt; &lt;br /&gt;The feature status is mostly on par with other X Elite machines, notably lacking: &lt;br /&gt; &lt;br /&gt;- USB-A and probably USB-over-Surface-connector &lt;br /&gt;- SD card reader (Realtek RTS5261 connected over PCIe) &lt;br /&gt;- Touchscreen and touchpad support (hid-over-SPI) &lt;br /&gt;- Keyboard support (low-hanging fruit, works with pending Surface EC changes) &lt;br /&gt;- Audio (a quick look suggests the setup is very close to the one in X1E CRD) &lt;br /&gt; &lt;br /&gt;The two Surface Laptop 7 SKUs (13.8" and 15") only have very minor differences, amounting close to none on the software side. Even the MBN firmware files and ACPI tables are shared between the two machines. &lt;br /&gt; &lt;br /&gt;With that in mind, support is added for both, although only the larger one was physically tested. Display differences will be taken care of through fused-in EDID and other matters should be solved within the EC and boot firmware."&lt;/blockquote&gt; &lt;br /&gt;With no working touchpad or keyboard support nor audio, for most Linux users this initial Microsoft Surface Laptop 7 support will be rather worthless. Hopefully Qualcomm engineers will be able to iron out all of these limitations in short order. &lt;br /&gt; &lt;br /&gt;Those interested in these initial Linux patches can find them on &lt;a href="https://lore.kernel.org/lkml/20240809-topic-sl7-v1-0-2090433d8dfc@quicinc.com/T/#m6e473fb8757b7a67fc51027f386416b101d70251"&gt;the kernel mailing list&lt;/a&gt;.&lt;/div&gt;</description>
    </item>
    <item>
      <title>EROFS-UTILS 1.8 Brings Multi-Threaded Compression, Intel IAA Acceleration, Initial Zstd</title>
      <link>https://www.phoronix.com/news/EROFS-UTILS-1.8-Released</link>
      <guid isPermaLink="true">https://www.phoronix.com/news/EROFS-UTILS-1.8-Released</guid>
      <pubDate>Fri, 09 Aug 2024 10:44:09 +0000</pubDate>
      <description>&lt;div class="content"&gt; &lt;div style="float: left; padding: 0 10px 10px;"&gt;&lt;img alt="LINUX STORAGE" src="https://www.phoronix.com/assets/categories/linuxstorage.webp" width="100" height="100" /&gt;&lt;/div&gt; For those making use of the &lt;a href="https://www.phoronix.com/search/EROFS"&gt;EROFS&lt;/a&gt; read-only file-system designed with mobile/embedded devices and containers in mind, EROFS-UTILS 1.8 is now available as an important update for these user-space utilities. &lt;br /&gt; &lt;br /&gt;EROFS-UTILS 1.8 is an important update to these user-space programs for making and managing EROFS file-systems. With EROFS-UTILS 1.8 there is now multi-threaded compression support with the &lt;em&gt;mkfs.erofs&lt;/em&gt; utility. Another big feature is now supporting the Intel IAA hardware accelerator using the QPL driver for those running modern Xeon Scalable systems. A third important change with EROFS-UTILS 1.8 is having initial support for Zstandard (Zstd) compression. &lt;br /&gt; &lt;br /&gt;The updated utilities also add support for multi-threading to EROFSFUSE, mkfs.erofs can now support incremental builds, various performance improvements to mkfs.erofs, and other fixes and improvements. &lt;br /&gt;&lt;p align="center"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=erofs" alt="EROFS logo" /&gt;&lt;/p&gt; &lt;br /&gt;Moving forward the EROFS developers are planning to continue working on incremental builds support, more multi-threading work for this read-only file-system creation, and compressed data deduplication. &lt;br /&gt; &lt;br /&gt;More details on the EROFS-UTILS 1.8 changes via the &lt;a href="https://lore.kernel.org/lkml/ZrViqMFpC6uVEoXK@debian/"&gt;release announcement&lt;/a&gt;.&lt;/div&gt;</description>
    </item>
    <item>
      <title>Linux Will Be Able To Boot ~0.035 Seconds Faster With One Line Kernel Patch</title>
      <link>https://www.phoronix.com/news/Linux-Faster-Boot-One-Line-ACPI</link>
      <guid isPermaLink="true">https://www.phoronix.com/news/Linux-Faster-Boot-One-Line-ACPI</guid>
      <pubDate>Fri, 09 Aug 2024 10:29:46 +0000</pubDate>
      <description>&lt;div class="content"&gt; &lt;div style="float: left; padding: 0 10px 10px;"&gt;&lt;img alt="LINUX KERNEL" src="https://www.phoronix.com/assets/categories/linuxkernel.webp" width="100" height="100" /&gt;&lt;/div&gt; The Linux kernel itself can already boot quite fast but with a simple one-line patch another ~0.035 seconds will be able to be shaved off the boot time.  &lt;br /&gt;  &lt;br /&gt;Intel Linux engineer Colin Ian King discovered that if aligning the slab in the ACPI code via the "SLAB_HWCACHE_ALIGN" flag will offer a measurable improvement in memory performance and reducing the kernel boot time.  &lt;br /&gt;  &lt;br /&gt;Colin explained with &lt;a href="https://lore.kernel.org/linux-acpi/20240808222138.51-1-colin.king@intel.com/"&gt;this one line kernel patch&lt;/a&gt;:  &lt;br /&gt;&lt;blockquote&gt;"Enabling SLAB_HWCACHE_ALIGN for the ACPI object caches improves boot speed in the ACPICA core for object allocation and free'ing especially in the AML parsing and execution phases in boot. Testing with 100 boots shows an average boot saving in acpi_init of ~35000 usecs compared to the unaligned version. Most of the ACPI objects being allocated and free'd are of very short life times in the critical paths for parsing and execution, so the extra memory used for alignment isn't too onerous."&lt;/blockquote&gt;  &lt;br /&gt;Linux has seen a lot of work on optimizing the kernel boot time, going back originally to the days of the netbooks craze and in the years since for better optimizing Linux servers...  &lt;br /&gt;&lt;p align="center"&gt;&lt;img src="https://www.phoronix.net/image.php?id=asus_eee_1201n&amp;image=asus_1201n_netbook9_med" alt="Eee PC throwback" /&gt;&lt;/p&gt;  &lt;br /&gt;A boot savings of around 0.035 seconds will be hardly noticeable to end-users but every little bit counts, especially in the case of hyperscalers and others needing to minimize downtime in the data center whether it be on bare metal servers or VMs. And for just being a one-line patch makes it all the more of an easy and nice win.&lt;/div&gt;</description>
    </item>
    <item>
      <title>Ryzen 3000 Series Gain Workaround For AMD P-State Linux Driver</title>
      <link>https://www.phoronix.com/news/AMD-Ryzen-3000-P-State-Quirk</link>
      <guid isPermaLink="true">https://www.phoronix.com/news/AMD-Ryzen-3000-P-State-Quirk</guid>
      <pubDate>Fri, 09 Aug 2024 10:17:02 +0000</pubDate>
      <description>&lt;div class="content"&gt; &lt;div style="float: left; padding: 0 10px 10px;"&gt;&lt;img alt="AMD" src="https://www.phoronix.com/assets/categories/amd.webp" width="100" height="100" /&gt;&lt;/div&gt; For those still running an AMD Ryzen 3000 series "Zen 2" desktop it really ought to be time to upgrade soon for better performance and power efficiency given &lt;a href="https://www.phoronix.com/review/ryzen-9600x-9700x"&gt;the Zen 5 performance benchmarks&lt;/a&gt; thus far, but for those still planning to use the Ryzen 3000 series for some time, a quirk/workaround is on the way for enabling more of those older platforms to work with the AMD P-State Linux driver. &lt;br /&gt; &lt;br /&gt;The AMD P-State driver can allow for better performance and power efficiency than the generic ACPI CPUFreq driver. However, for Zen 2 where ACPI CPPC support was originally introduced, a number of Ryzen 3000 systems have missing nominal frequency (nominal_freq) and lowest frequency (lowest_freq) parameters in their ACPI tables. That missing data in turn has caused issues when trying to use the AMD P-State driver. &lt;br /&gt;&lt;p align="center"&gt;&lt;img src="https://www.phoronix.net/image.php?id=amd-ryzen9-3950x&amp;image=amd_3950x_1_med" alt="Ryzen 9 3900X" /&gt;&lt;/p&gt; &lt;br /&gt;&lt;a href="https://lore.kernel.org/linux-pm/20240809060905.777146-1-perry.yuan@amd.com/"&gt;This patch&lt;/a&gt; should fix things up for the Ryzen 3000 series as the quirk will fall-back to using static values for the lowest frequency and nominal frequency parameters. The patch is currently being reviewed and could be picked up for the Linux v6.12 cycle later in the year.&lt;/div&gt;</description>
    </item>
    <item>
      <title>Canonical Moves To Shipping Very Latest Upstream Kernel Code For Ubuntu Releases</title>
      <link>https://www.phoronix.com/news/Ubuntu-Releases-Fresher-Kernels</link>
      <guid isPermaLink="true">https://www.phoronix.com/news/Ubuntu-Releases-Fresher-Kernels</guid>
      <pubDate>Fri, 09 Aug 2024 02:19:24 +0000</pubDate>
      <description>&lt;div class="content"&gt; &lt;div style="float: left; padding: 0 10px 10px;"&gt;&lt;img alt="UBUNTU" src="https://www.phoronix.com/assets/categories/ubuntu.webp" width="100" height="100" /&gt;&lt;/div&gt; Following decisions like &lt;a href="https://www.phoronix.com/review/ubuntu-o3-experiment"&gt;exploring -O3 package builds for Ubuntu Linux&lt;/a&gt;, another newly-announced change by Canonical I must applaud is their decision to commit to shipping the very latest upstream kernel code at release time.  &lt;br /&gt;  &lt;br /&gt;Ubuntu up to now for each release has shipped with the latest upstream kernel release as of kernel freeze time. But in some cases this means even shipping with a ~2 month old kernel version even if a new upstream Linux kernel release is near and will be stable ahead of the next planned Ubuntu Linux release. So now there's a shift in course by Canonical's kernel team for Ubuntu to accommodate that difference so the Ubuntu Linux release will be shipping with the very latest upstream kernel at release time.  &lt;br /&gt;  &lt;br /&gt;This is great and the right move though it stops short of Ubuntu Linux shifting to a policy like new kernel versions coming down as stable release updates over the lifetime of Ubuntu releases.  &lt;br /&gt;  &lt;br /&gt;Today's &lt;a href="https://discourse.ubuntu.com/t/kernel-version-selection-for-ubuntu-releases/47007"&gt;kernel version selection announcement&lt;/a&gt; sums it up as:  &lt;br /&gt;&lt;blockquote&gt;Current Policy  &lt;br /&gt;  &lt;br /&gt;The way the CKT has historically chosen an upstream Linux kernel version was with a conservative ‘wait and see’ approach. Given the month-long stabilization window required, an upstream kernel version all but certain to be released would be the tentative selection, with a possible last minute jump to a more recent version should it turn out to release in a workable time-frame. This approach would guarantee stability on the appointed release day, but was proving unpopular with consumers looking to adopt the latest features and hardware support as well as silicon vendors looking for a firmer version commitment to align their Ubuntu support.  &lt;br /&gt;  &lt;br /&gt;New Policy  &lt;br /&gt;  &lt;br /&gt;The intent behind this post is to describe a new policy the CKT is taking in regards to kernel version selection for an upcoming Ubuntu release. To provide users with the absolute latest in features and hardware support, Ubuntu will now ship the absolute latest available version of the upstream Linux kernel at the specified Ubuntu release freeze date, even if upstream is still in Release Candidate (RC) status.&lt;/blockquote&gt;  &lt;br /&gt;This is a nice improvement to see by Canonical for ensuring the freshest upstream kernel version is shipped as of the Ubuntu release time.  &lt;br /&gt;&lt;p align="center"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=ubuntu_newer_kernels2" alt="Ubuntu kernel selection for 24.10" /&gt;&lt;/p&gt;  &lt;br /&gt;In turn this means for the upcoming Ubuntu 24.10 release it should solidly be the Linux 6.11 kernel. It would still be nice if Ubuntu would commit resources to allow shipping new upstream kernel versions down as stable release updates, but that is a battle for another day.&lt;/div&gt;</description>
    </item>
    <item>
      <title>AMD Ryzen 7 9700X Performance With DDR5-8000</title>
      <link>https://www.phoronix.com/review/ryzen-7-9700x-ddr5-8000</link>
      <guid isPermaLink="true">https://www.phoronix.com/review/ryzen-7-9700x-ddr5-8000</guid>
      <pubDate>Fri, 09 Aug 2024 01:08:00 +0000</pubDate>
      <description>&lt;div class="content"&gt;   &lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2024&amp;image=corsair_ddr5_8000_1_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=corsair_ddr5_8000_1_med" alt="Corsair Vengeance DDR5-8000 kit" /&gt;&lt;/a&gt;&lt;/p&gt;  &lt;p&gt;With the new AMD Ryzen 9000 series processors the AGESA supports up to DDR5-8000 memory. With yesterday's testing of the &lt;a href="https://www.phoronix.com/review/ryzen-9600x-9700x"&gt;AMD Ryzen 5 9600X and Ryzen 7 9700X review&lt;/a&gt; all of the tests were done at DDR5-6000 in matching with the Ryzen 7000 series and Intel Core 13th/14th Gen configurations. In this article today is an initial look at the DDR5-8000 performance with the AMD Ryzen 7 9700X while using Corsair Vengeance 2 x 16GB DDR5-8000 DIMMs (Corsair CMH32GX5M2X8000C36).&lt;/p&gt;  &lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2024&amp;image=corsair_ddr5_8000_2_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=corsair_ddr5_8000_2_med" alt="Corsair Vengeance DDR5-8000 DIMMs" /&gt;&lt;/a&gt;&lt;/p&gt;  &lt;p&gt;Today's article is a very preliminary look at the DDR5-8000 performance with the Zen 5 desktop processors and is simply comparing some common DDR5-6000 DIMMs to DDR5-8000. After the Ryzen 9 9900X/9950X launch will be a more thorough look at the DDR5-8000 memory performance with more benchmarks and other DIMM kits as well.&lt;/p&gt;  &lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2024&amp;image=corsair_ddr5_8000_3_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=corsair_ddr5_8000_3_med" alt="Corsair Vengeance DDR5-8000 CMH32GX5M2X8000C36" /&gt;&lt;/a&gt;&lt;/p&gt;  &lt;p&gt;For this initial AMD Ryzen 9000 series DDR5-8000 testing I ordered the Corsair CMH32GX5M2X8000C36 kit. For $199 USD these days it's possible to buy a 2 x 16GB DDR5-8000 memory kit. These Corsair Vengeance RGB DDR5-8000 DIMMs are tested at 36-48-48-98 latencies at 1.5V. The Corsair product page just advertises the CMH32GX5M2X8000C36 as for Intel 700 Series motherboards with 13th Gen Intel Core CPUs and newer but did work out with the Ryzen 7 9700X testing on the ASUS ROG STRIX X670-E GAMING WIFI motherboard.&lt;/p&gt;  &lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2024&amp;image=corsair_ddr5_8000_4_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=corsair_ddr5_8000_4_med" alt="Corsair Vengeance DDR5-8000 with Ryzen 7 9700X configuration" /&gt;&lt;/a&gt;&lt;/p&gt;  &lt;p&gt;The Corsair CMH32GX5M2X8000C36 were running fine on this Ryzen 7 9700X + ASUS ROG STRIX X670-E GAMING WIFI at DDR5-8000 with 36-48-48-98 timings at 1.5V. This was available via DOCP and quickly up and running with ease. For comparison in this initial article are the Corsair DDR5-8000 2 x 16GB results up against the 2 x 16GB G Skill F5-6000J3038F16G DDR5-6000 DIMMs that I was using on this system for my review benchmarks and previously on this X670E board. The G Skill F5-6000J3038F16G allows running at DDR5-6000 with 30-38-38-96 timings at 1.35V.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="https://phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/result.svgz" alt="AMD Ryzen 9700X DDR5-8000" /&gt;&lt;/div&gt;  &lt;p&gt;From Ubuntu 24.04 LTS with the Linux 6.10 kernel I then proceeded to run a round of benchmarks comparing this 2 x 16GB DDR5-6000 30-38-38-96 versus 2 x 16GB DDR5-8000 36-48-48-98 memory with a mix of synthetic and real-world workloads for seeing where the DDR5-8000 memory is able to pay off or not with the greater bandwidth but UCLK running 1:2 rather than 1:1 for attaining the higher speed.&lt;/p&gt;  &lt;/div&gt;&lt;div class="content"&gt;   &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/ramspeed-smp-copy-integer.svgz" alt="RAMspeed SMP benchmark with settings of Type: Copy, Benchmark: Integer. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/ramspeed-smp-scale-integer.svgz" alt="RAMspeed SMP benchmark with settings of Type: Scale, Benchmark: Integer. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/ramspeed-smp-average-integer.svgz" alt="RAMspeed SMP benchmark with settings of Type: Average, Benchmark: Integer. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/mbw-mcfbs-8192-mib.svgz" alt="MBW benchmark with settings of Test: Memory Copy, Fixed Block Size, Array Size: 8192 MiB. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;In various synthetic memory benchmarks, going for the DDR5-8000 obviously makes for measurable uplift.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/high-performance-conjugate-gradient-104-104-104-60.svgz" alt="High Performance Conjugate Gradient benchmark with settings of X Y Z: 104 104 104, RT: 60. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;With HPC benchmarks like HPCG there was some small uplift going for the DDR5-8000 DIMMs. HPCG though sees a bigger difference if say opting for a CPU with 3D V-Cache.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/nas-parallel-benchmarks-btc.svgz" alt="NAS Parallel Benchmarks benchmark with settings of Test / Class: BT.C. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/nas-parallel-benchmarks-epc.svgz" alt="NAS Parallel Benchmarks benchmark with settings of Test / Class: EP.C. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/nas-parallel-benchmarks-ftc.svgz" alt="NAS Parallel Benchmarks benchmark with settings of Test / Class: FT.C. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/nas-parallel-benchmarks-isd.svgz" alt="NAS Parallel Benchmarks benchmark with settings of Test / Class: IS.D. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/nas-parallel-benchmarks-luc.svgz" alt="NAS Parallel Benchmarks benchmark with settings of Test / Class: LU.C. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/nas-parallel-benchmarks-mgc.svgz" alt="NAS Parallel Benchmarks benchmark with settings of Test / Class: MG.C. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/nas-parallel-benchmarks-spb.svgz" alt="NAS Parallel Benchmarks benchmark with settings of Test / Class: SP.B. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/gromacs-mpi-cpu-water_gmx50_bare.svgz" alt="GROMACS benchmark with settings of Implementation: MPI CPU, Input: water_GMX50_bare. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;In a number of the HPC oriented benchmarks there were some nice gains to find in going for DDR5-8000 memory on this AMD Ryzen 9000 series system, but in some cases the performance went the other direction.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/quicksilver-coral2-p1.svgz" alt="Quicksilver benchmark with settings of Input: CORAL2 P1. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/namd-aw35a.svgz" alt="NAMD benchmark with settings of Input: ATPase with 327,506 Atoms. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/namd-sw106a.svgz" alt="NAMD benchmark with settings of Input: STMV with 1,066,628 Atoms. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;In some workloads the DDR5-8000 memory was behind the DDR5-6000 memory due to the UCLK running 1:2 for the higher memory speed.&lt;/p&gt;  &lt;/div&gt;&lt;div class="content"&gt;   &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/xcompact3d-incompact3d-ii1cpd-1.svgz" alt="Xcompact3d Incompact3d benchmark with settings of Input: input.i3d 193 Cells Per Direction. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/openfoam-dsms-execution-time.svgz" alt="OpenFOAM benchmark with settings of Input: drivaerFastback, Small Mesh Size, Execution Time. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;Ultimately it comes down to what workloads you are running if they are more memory bandwidth intensive. For cases like OpenFOAM CFD and Incompact3D are some meaningful improvements if going for DDR5-8000 memory.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/openradioss-chrysler-neon-1m.svgz" alt="OpenRadioss benchmark with settings of Model: Chrysler Neon 1M. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/specfem3d-mount-st-helens.svgz" alt="SPECFEM3D benchmark with settings of Model: Mount St. Helens. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;It will be fun to continue this DDR5-8000 exploration more broadly with the Ryzen 9 9900 series that typically will see more HPC-type usage than a Ryzen 7.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/luxcorerender-dlsc-cpu.svgz" alt="LuxCoreRender benchmark with settings of Scene: DLSC, Acceleration: CPU. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/luxcorerender-danish-mood-cpu.svgz" alt="LuxCoreRender benchmark with settings of Scene: Danish Mood, Acceleration: CPU. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/embree-pathtracer-ispc-crown.svgz" alt="Embree benchmark with settings of Binary: Pathtracer ISPC, Model: Crown. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/embree-pathtracer-ispc-asian-dragon.svgz" alt="Embree benchmark with settings of Binary: Pathtracer ISPC, Model: Asian Dragon. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/blender-bmw27-cpu-only.svgz" alt="Blender benchmark with settings of Blend File: BMW27, Compute: CPU-Only. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/blender-junkshop-cpu-only.svgz" alt="Blender benchmark with settings of Blend File: Junkshop, Compute: CPU-Only. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/blender-barbershop-cpu-only.svgz" alt="Blender benchmark with settings of Blend File: Barbershop, Compute: CPU-Only. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;For the rendering workloads they tended to favor the DDR5-6000 memory with tighter timings.&lt;/p&gt;  &lt;/div&gt;&lt;div class="content"&gt;   &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/timed-linux-kernel-compilation-defconfig.svgz" alt="Timed Linux Kernel Compilation benchmark with settings of Build: defconfig. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/timed-linux-kernel-compilation-allmodconfig.svgz" alt="Timed Linux Kernel Compilation benchmark with settings of Build: allmodconfig. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/timed-llvm-compilation-ninja.svgz" alt="Timed LLVM Compilation benchmark with settings of Build System: Ninja. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;Various code compilation benchmarks were yielding the better performance with the DDR5-6000 memory due to the UCLK running 1:2 for memory speeds above DDR5-6000.&lt;/p&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/memcached-15.svgz" alt="Memcached benchmark with settings of Set To Get Ratio: 1:5. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/memcached-110.svgz" alt="Memcached benchmark with settings of Set To Get Ratio: 1:10. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/memcached-1100.svgz" alt="Memcached benchmark with settings of Set To Get Ratio: 1:100. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/pytorch-cpu-64-resnet-50.svgz" alt="PyTorch benchmark with settings of Device: CPU, Batch Size: 64, Model: ResNet-50. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/tensorflow-cpu-64-resnet-50.svgz" alt="TensorFlow benchmark with settings of Device: CPU, Batch Size: 64, Model: ResNet-50. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/openvino-vdfi-cpu.svgz" alt="OpenVINO benchmark with settings of Model: Vehicle Detection FP16-INT8, Device: CPU. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/openvino-fdrfi-cpu.svgz" alt="OpenVINO benchmark with settings of Model: Face Detection Retail FP16-INT8, Device: CPU. DDR5-6000 was the fastest." /&gt;&lt;/div&gt;  &lt;div style="text-align: center;"&gt;&lt;img type="image/svg+xml" width="100%" height="auto" src="//phoronix.com/benchmark/result/amd-ryzen-9700x-ddr5-8000/llamacpp-meta-llama-3-8b-instruct-q8_0gguf.svgz" alt="Llama.cpp benchmark with settings of Model: Meta-Llama-3-8B-Instruct-Q8_0.gguf. DDR5-8000 was the fastest." /&gt;&lt;/div&gt;  &lt;p&gt;Ultimately it comes down to what applications/workloads are most important to you in deciding whether going for DDR5-8000 memory makes sense with its higher latencies with current DIMM kits available. More benchmarks can be found on &lt;a href="https://openbenchmarking.org/result/2408072-NE-RYZEN970047"&gt;this result page&lt;/a&gt;. Stay tuned for more DDR5-8000 memory testing with additional DIMM kits when getting to the Ryzen 9 9900 series.&lt;/p&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>OpenBLAS 0.3.28 Brings More Optimizations, Meteor Lake &amp; Emerald Rapids Support</title>
      <link>https://www.phoronix.com/news/OpenBLAS-0.3.28</link>
      <guid isPermaLink="true">https://www.phoronix.com/news/OpenBLAS-0.3.28</guid>
      <pubDate>Fri, 09 Aug 2024 01:06:07 +0000</pubDate>
      <description>&lt;div class="content"&gt; &lt;div style="float: left; padding: 0 10px 10px;"&gt;&lt;img alt="PROGRAMMING" src="https://www.phoronix.com/assets/categories/programming.webp" width="100" height="100" /&gt;&lt;/div&gt; OpenBLAS 0.3.28 made it out today as the open-source optimized BLAS library that caters to a wide range of processors spanning various architectures. With this OpenBLAS 0.3.28 release are yet more optimizations and new CPU optimized paths. &lt;br /&gt; &lt;br /&gt;OpenBLAS 0.3.28 reworks its "HUGETLB" implementation from GotoBLAS, improves multi-threaded GEMM performance for certain matrices, improved BLAS3 performance on large multi-core systems via enhanced parallelism, improved performance of initial memory allocation, and a range of other common optimizations and fixes. &lt;br /&gt; &lt;br /&gt;OpenBLAS 0.3.28 also brings official support for Intel Xeon Emerald Rapids and Intel Core Ultra (Meteor Lake) processors. There is also now auto-detection of Zhaoxin KX-7000 CPUs, fixing auto-detection for old Intel Prescott CPUs, improved compiler options for CMake and LLVM builds on AVX-512 capable targets, and other x86_64 optimizations. &lt;br /&gt;&lt;p align="center"&gt;&lt;img src="https://www.phoronix.net/image.php?id=intel-xeon-platinum-8592&amp;image=intel_xeon8592_3_med" alt="Intel Xeon Platinum Emerald Rapids CPU" /&gt;&lt;/p&gt; &lt;br /&gt;Over on the ARM64 side is improved GEMM performance on the Arm Neoverse V1, new optimized kernels for the A64FX, and other changes. There are also a number of LoongArch, RISC-V, and POWER optimizations too in this BLAS library update. &lt;br /&gt; &lt;br /&gt;Downloads and more details on OpenBLAS 0.3.28 for this leading open-source BLAS implementation via &lt;a href="https://github.com/OpenMathLib/OpenBLAS/releases/tag/v0.3.28"&gt;GitHub&lt;/a&gt;.&lt;/div&gt;</description>
    </item>
    <item>
      <title>System76 Releases COSMIC Alpha Desktop - It's Looking Quite Interesting</title>
      <link>https://www.phoronix.com/news/System76-COSMIC-Alpha</link>
      <guid isPermaLink="true">https://www.phoronix.com/news/System76-COSMIC-Alpha</guid>
      <pubDate>Thu, 08 Aug 2024 15:27:51 +0000</pubDate>
      <description>&lt;div class="content"&gt; &lt;div style="float: left; padding: 0 10px 10px;"&gt;&lt;img alt="DESKTOP" src="https://www.phoronix.com/assets/categories/desktop.webp" width="100" height="100" /&gt;&lt;/div&gt; System76 today is releasing an alpha build of Pop!_OS 24.04 that is built atop Ubuntu 24.04 LTS and making it very interesting is that it includes the alpha version of their Rust-written COSMIC desktop environment. I've been playing around with this Pop!_OS 24.04 alpha in advance of today's embargo lift and it's been working out quite well. &lt;br /&gt; &lt;br /&gt;COSMIC is an interesting Rust-based desktop environment that System76 has been developing. It's focus is on their Pop!_OS distribution but there have been other distributions like Serpent OS expressing interest as well along with the likes of Redox OS. &lt;br /&gt;&lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2024&amp;image=cosmic_alpha_1_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=cosmic_alpha_1_med" alt="COSMIC desktop" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;br /&gt;&lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2024&amp;image=cosmic_alpha_2_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=cosmic_alpha_2_med" alt="COSMIC desktop" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;br /&gt;COSMIC is a Wayland-native desktop but does support XWayland. It has all the usual features one would expect from a compositor including fractional scaling and being able to cope with NVIDIA hybrid graphics. COSMIC continues supporting auto-tiling along with various other windowing features. &lt;br /&gt;&lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2024&amp;image=cosmic_alpha_3_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=cosmic_alpha_3_med" alt="COSMIC desktop" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;br /&gt;&lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2024&amp;image=cosmic_alpha_4_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=cosmic_alpha_4_med" alt="COSMIC desktop" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;br /&gt;The alpha release of COSMIC is off to a nice start but some features missing like the copy/paste not working with their text editor. System76 also has to finish up work on the settings area, variable refresh rate, the COSMIC Files file manager, and other refinements. &lt;br /&gt;&lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2024&amp;image=cosmic_alpha_5_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=cosmic_alpha_5_med" alt="COSMIC desktop" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;br /&gt;&lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2024&amp;image=cosmic_alpha_6_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=cosmic_alpha_6_med" alt="COSMIC desktop" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;br /&gt;The stable release of Pop!_OS 24.04 and COSMIC will take place later in the year. &lt;br /&gt;&lt;p align="center"&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2024&amp;image=cosmic_alpha_7_lrg" target="_blank"&gt;&lt;img src="https://www.phoronix.net/image.php?id=2024&amp;image=cosmic_alpha_7_med" alt="COSMIC desktop" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;br /&gt;COSMIC is off to a nice start and those wanting to learn more or give the alpha ISO a whirl can find the details on &lt;a href="https://system76.com/cosmic"&gt;System76.com&lt;/a&gt;.&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
